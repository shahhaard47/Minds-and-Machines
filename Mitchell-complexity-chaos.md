## Complexity from simplicity

It is difficult to backtrack the origins of a learnt behavior. However, the complex set of behaviors may have arisen from a certain simple set of rules that human beings have evolved to abide by. In her [*Complexity A Guided Tour*](https://drive.google.com/file/d/0B4me4PbBMBmOa2VpUHdUYWZWdXM/view), Melanie Mitchell defines complexity as “a system in which large networks of components with no central control and simple rules of operation give rise to complex collective behavior, sophisticated information processing, and adaptation via learning or evolution.” The theory of complexity is incredibly interesting because it can provide more comprehensive insights into the learning process. The analogies Mitchell draws between the emergent complex nature of the brain produced by simple rules followed by individual neurons and other similar systems such as the immune system, insect colonies, the world wide web, etc. helps us realize the commonalities among such systems. Furthermore, Mitchell’s discussion of dynamic systems and chaos in chapter two helps us understand the unpredictable nature. Finally, merely acknowledging the efficacy of such complex systems, understanding their key properties, and understanding the root of their chaos can be used to justify the effective nature of, seemingly magical, artificial neural networks. 

First, Mitchell describes three key properties of complex systems: complex collective behavior, signaling and information processing, and adaption. Individual neurons, “simple components” of the brain, perform the task of receiving signals from other neurons and based on the signals received, makes the decision to signal or alert other neurons. That is the extent of each neuron’s responsibility, to perform simple tasks with no central control or leader. The collective actions of about [100 billion](http://www.human-memory.net/brain_neurons.html) of such neurons “gives rise to the [brain’s] complex, hard-to-predict, and challenging patterns of behavior that fascinate us” (Mitchell). Overtime, the configuration and/or characteristic of these individual components adapt, “that is, change their behavior to improve their chances of survival or success, through learning or evolutionary processes” (Mitchell). 

Furthermore, in chapter two, Mitchell describes the gradual discovery of chaotic systems, as those with “sensitive dependence on initial conditions.” She also pinpoints physicist James Maxwell’s account of such systems in 1873: “there are classes of phenomena affected by Influences whose physical magnitude is too small to be taken into account by a finite being, [but which] may produce results of the highest importance.” Subsequently, the distinguished Logistic Map equation is used to demonstrate the chaotic nature of a system. Subsequently, through the famous Logistic Map equation and many other examples of chaotic systems, she demonstrates extreme sensitivity to initial inputs as well as highlights their deterministic, yet practically impossible to predict nature. 

Finally, artificial neural networks manifest many of the properties of complex / chaotic systems. For instance, they too are made up of individual simple components, also known as neurons or simply nodes. Analogously to biological neurons, these nodes receive signal from the multiple other nodes as input and output a corresponding signal depending on their learned (demonstrates adaptiveness) responsiveness to the signals received. Collectively, the nodes form a network, which successfully performs exceedingly intricate tasks such as object detection/classification and natural language processing.

Sources:

http://www.human-memory.net/brain_neurons.html 
https://drive.google.com/file/d/0B4me4PbBMBmOa2VpUHdUYWZWdXM/view 
